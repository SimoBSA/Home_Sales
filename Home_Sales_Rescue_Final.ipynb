{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d539bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install Java and PySpark\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!pip install -q pyspark\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, round, year\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder.appName(\"HomeSales\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d04ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download and read CSV with semicolon delimiter\n",
    "!wget -q https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").option(\"sep\", \";\").option(\"inferSchema\", \"true\").csv(\"home_sales_revised.csv\")\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "df.createOrReplaceTempView(\"home_sales\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73221cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT year(date) AS year_sold, ROUND(AVG(price), 2) AS avg_price\n",
    "    FROM home_sales\n",
    "    WHERE CAST(bedrooms AS INT) = 4\n",
    "    GROUP BY year_sold\n",
    "    ORDER BY year_sold\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT date_built, ROUND(AVG(price), 2) AS avg_price\n",
    "    FROM home_sales\n",
    "    WHERE CAST(bedrooms AS INT) = 3 AND CAST(bathrooms AS INT) = 3\n",
    "    GROUP BY date_built\n",
    "    ORDER BY date_built\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291094d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT date_built, ROUND(AVG(price), 2) AS avg_price\n",
    "    FROM home_sales\n",
    "    WHERE CAST(bedrooms AS INT) = 3 AND CAST(bathrooms AS INT) = 3 AND CAST(floors AS INT) = 2 AND sqft_living >= 2000\n",
    "    GROUP BY date_built\n",
    "    ORDER BY date_built\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f841e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT view, ROUND(AVG(price), 2) AS avg_price\n",
    "    FROM home_sales\n",
    "    GROUP BY view\n",
    "    HAVING avg_price >= 350000\n",
    "    ORDER BY view\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"Runtime:\", round(time.time() - start_time, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.cacheTable(\"home_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is 'home_sales' cached?:\", spark.catalog.isCached(\"home_sales\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT view, ROUND(AVG(price), 2) AS avg_price\n",
    "    FROM home_sales\n",
    "    GROUP BY view\n",
    "    HAVING avg_price >= 350000\n",
    "    ORDER BY view\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"Cached Runtime:\", round(time.time() - start_time, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f27115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.partitionBy(\"date_built\").mode(\"overwrite\").parquet(\"/tmp/home_sales_partitioned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d6321",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_df = spark.read.parquet(\"/tmp/home_sales_partitioned\")\n",
    "parquet_df.createOrReplaceTempView(\"home_sales_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0714e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT view, ROUND(AVG(price), 2) AS avg_price\n",
    "    FROM home_sales_parquet\n",
    "    GROUP BY view\n",
    "    HAVING avg_price >= 350000\n",
    "    ORDER BY view\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"Parquet Runtime:\", round(time.time() - start_time, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec475ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.uncacheTable(\"home_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a756933",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is 'home_sales' cached after uncache?:\", spark.catalog.isCached(\"home_sales\"))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
